<h1>More Concurrency Synchronization Techniques</h1>

<p>
The <a href="channel-use-cases.html">channel use cases</a> article introduces
many use cases where channels are used to do data synchronizations among goroutines.
In fact, channels are not the only synchronization techniques provided in Go.
There are some other synchronization techniques supported by Go.
For some specific circumstances, using the synchronization techniques
other than channel are more efficient and readable than using channels.
Below will introduce these synchronization techniques.
</p>

<h3>The Techniques Provided In The <code>sync</code> Standard Package</h3>

<p>
The <code>sync</code> standard package provides several types
which can be used to do synchronizations for some specialized circumstances.
and guarantee some specialized memory orders.
For the specialized circumstances, these techniques are more efficient,
and look cleaner, than the channel ways.
</p>

<p><i>
(Please note, to avoid abnormal behaviors, it is best never to copy
the values of the types in the <code>sync</code> standard package.)
</i></p>

<p>
The 
</p>

<h4>The <code>sync.WaitGroup</code> Type</h4>

<div>
<p>
Each <code>WaitGroup</code> value maintains a counter internally.
We can call the <code>Add</code> method on a <code>WaitGroup</code> value
to change the value of the counter maintained by the <code>WaitGroup</code> value.
A <code>Done()</code> method call on a <code>WaitGroup</code> value
is just a shortcut of a <code>Add(-1)</code> on the <code>WaitGroup</code> value.
The counters should be never negative. If such a counter becomes negative, panic will happen.
</p>

<p>
A goroutine can call the <code>Wait</code> method on a <code>WaitGroup</code> value
to wait the counter maintained by the <code>WaitGroup</code> value becomes zero.
If the counter is already zero when the <code>Wait</code> method is called,
the the <code>Wait</code> method call can be viewed as a no-op,
otherwise, the caller goroutine will enter the blocking state.
</p>

<p>
If a goroutine enters the blocking state by
calling the <code>Wait</code> method on a <code>WaitGroup</code> value,
it will enter the running state again (a.k.a., the <code>Wait</code> method call returns) 
when another goroutine modifies the counter of the <code>WaitGroup</code> value to zero,
generally by calling the <code>Done()</code> method on the <code>WaitGroup</code> value.
This call to <code>Done()</code> method is guaranteed to happen
before the the <code>Wait</code> method call returns.
</p>

Example:

<pre class="line-numbers"><code class="language-go">package main

import (
	"fmt"
	"math/rand"
	"sync"
	"time"
)

const N = 5
var values [N]int32

func main() {
	rand.Seed(time.Now().UnixNano())
	
	var wg sync.WaitGroup
	wg.Add(N)
	for i := 0; i < N; i++ {
		i := i
		go func() {
			values[i] = 50 + rand.Int31n(50)
			fmt.Println("Done: ", i)
			wg.Done() // <=> wg.Add(-1)
		}()
	}
	
	wg.Wait()
	fmt.Println("values: ", values)
}
</code></pre>

In the above example, the main goroutine waits until all other <code>N</code> goroutines
have populated their respective element value in <code>values</code> array.
Here is one possible output result:
<pre class="output">
Done:  4
Done:  1
Done:  3
Done:  0
Done:  2
values:  [71 89 50 62 60]
</pre>

We can split the only <code>Add</code> method call in the above example into multiple ones.
<pre class="line-numbers"><code class="language-go">func main() {
	rand.Seed(time.Now().UnixNano())
	
	var wg sync.WaitGroup
	for i := 0; i < N; i++ {
		wg.Add(1) // will be invoked N times
		i := i
		go func() {
			values[i] = 50 + rand.Int31n(50)
			wg.Done()
		}()
	}
	
	wg.Wait()
}
</code></pre>

The <code>Wait</code> method can be called in multiple goroutines.
When the counter becomes zero, all of them will be notified, in a broadcast way.

<pre class="line-numbers"><code class="language-go">var wg sync.WaitGroup
wg.Add(1)

for i := 0; i < N; i++ {
	i := i
	go func() {
		wg.Wait()
		fmt.Printf("values[%v]=%v \n", i, values[i])
	}()
}

for i := 0; i < N; i++ {
	values[i] = 50 + rand.Int31n(50)
}
wg.Done() // will make a broadcast
</code></pre>

</div>

<h4>The <code>sync.Once</code> Type</h4>

<div>
<p>
An <code>Once</code> value has a <code>Do</code> method,
which takes only one parameter, of function type <code>func()</code>.
A <code>Do</code> method call will try to invoke its argument (which is a function).
The <code>Do</code> method of an <code>Once</code> value
can be called multiple times, in multiple goroutines.
But only one argument function (exactly) of these calls will be invoked.
The invoked argument function is guaranteed to return before any <code>Do</code> method call returns.
In other words, the code in the invoked argument function
is guaranteed to be executed before any <code>Do</code> method call returns.
</p>

<p>
Generally, <code>Once.Do</code> methods are used to ensure that
something has been done and only done once in concurrent programming.
</p>

Example:
<pre class="line-numbers"><code class="language-go">package main

import (
	"log"
	"sync"
)

func main() {
	log.SetFlags(0)
	
	doSomething := func() {
		log.Println("Hello")
	}
	
	var wg sync.WaitGroup
	var once sync.Once
	for i := 0; i < 5; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			once.Do(doSomething)
			log.Println("world!")
		}()
	}
	
	wg.Wait()
}
</code></pre>

<p>
In th above example, <code>Hello</code> will be output once,
but <code>world!</code> will be output five times.
And <code>Hello</code> is guaranteed to be output before all five <code>world!</code>.
</p>

</div>

<h4>The <code>sync.Cond</code> Type</h4>

multiple conds can share lockers.

<h4>The <code>sync.Mutex</code> Type</h4>

<div>
<p>
Each <code>Mutex</code> value is a mutual exclusion lock.
The method <code>Lock</code> and <code>Unlock</code> are used to lock and unlock a <code>Mutex</code> value.
A <code>Mutex</code> value can be locked at most once at the same time.
An already locked <code>Mutex</code> value can only be locked again if it gets unlocked.
The <b>n</b>th unlock on a <code>Mutex</code> value is guarantted to happen
before the (<b>n+1</b>)th lock on the same <code>Mutex</code> value returns.
</p>

<p>
The zero <code>Mutex</code> value is unlocked. 
</p>

Generally, a <code>Mutex</code> value is used to guard a piece of code snippet,
so that the piece of code snippet will not access any data parallelly.
An example:
<pre class="line-numbers"><code class="language-go">package main

import "sync"

type Counter struct {
	m sync.Mutex
	n uint64
}

func (c *Counter) Add(delta uint64) {
	c.m.Lock()
	c.n += delta
	c.m.Unlock()
}

func (c *Counter) Value() uint64 {
	c.m.Lock()
	defer c.m.Unlock()
	return c.n
}

func main() {
	var done = make(chan struct{})
	var c Counter
	for i := 0; i < 100; i++ {
		go func() {
			c.Add(1)
			if c.Value() == 100 {
				done <- struct{}{}
				
				/*
				select {
				default:
				case done <- struct{}{}:
				}
				*/
			}
		}()
	}
	<- done
}
</code></pre>

<p>
In the above example, the <code>Mutex</code> field of any <code>Counter</code> value
will guarantee that the <code>n</code> field of the <code>Counter</code> value
will be never accessed by multiple goroutines parallelly.
</p>

<p>
A <code>Mutex</code> value can also be used to make notifications.
</p>
</div>

<h4>The <code>sync.RWMutex</code> Type</h4>

<h3>Atomic Operations</h3>

<p>
The <code>sync/atomic</code> standard package provides
some functions to do atomic operations.
Atomic operations are more primitive than other synchronization techniques.
In fact, atomic operations are often used in implementing other synchronization techniques.
</p>

<h3>Make Using Of Network And File IO</h3>

<p>
We can also do synchronizations through network and file IO.
But such techniques are very inefficient whthin a single program process.
Generally, they are used in inter-process and distributed synchronizations.
Go 101 will not explain how to such techniques.
</p>

<!---
https://golang.org/ref/mem


https://github.com/golang/go/issues/5045#issuecomment-292673178
C++ atomics and memory ordering 
https://bartoszmilewski.com/2008/12/01/c-atomics-and-memory-ordering/
Memory ordering
https://en.wikipedia.org/wiki/Memory_ordering
Cmd/compile: Go 1.8 regression: sync/atomic loop elided
https://news.ycombinator.com/item?id=13686863


https://groups.google.com/forum/#!topic/golang-nuts/D4DwnG4012E

other data synchronization methods (including other messaging ways, such as network IO)

WaitGroup.Wait可以在多个goroutine中调用，将同时被notify.

if the transferred values are ignored, channel == mutex

buffer channel, sender and receiver don't kwno when the peer will ...

Note that it's not just the compiler.  As I was saying on another
thread earlier today, it's also the memory ordering of the processor. 

goroutine states
* suspended
* blocking
* running
  * sleeping


map sync


a channel is a bridge to exchange the ownership of values among goroutines.

try to one directional channels.

runtime.Goexit() terminates the goroutine that calls it. 

sync.Pool is drained during garbage collection.
sync.Pool is cleared before garbage collection, so it never retains unnecessary memory.

https://groups.google.com/forum/#!msg/golang-nuts/AoO3aivfA_E/zFjhu8XvngMJ
We generally don’t want sync/atomic to be used at all…Experience has shown us again and again that very very few people are capable of writing correct code that uses atomic operations…If we had thought of internal packages when we added the sync/atomic package, perhaps we would have used that. Now we can’t remove the package because of the Go 1 guarantee.

https://dave.cheney.net/2015/11/18/wednesday-pop-quiz-spot-the-race
substle data race
mix non-pointer and pointer receivers ...

atomic.AddUintUintXX (p, -N)

atomic.CompareAndSwapUint64 may be failed, so need retry

https://en.wikipedia.org/wiki/Memory_barrier 

https://groups.google.com/forum/#!topic/golang-nuts/AoO3aivfA_E

https://news.ycombinator.com/item?id=13686863

For the complexity and subtlety of properly using atomic functions, atomic functions are not recommanded
to synchronize values. Mutexes are more preferred.
Some Go team members are regreted that the atomic package is expose as a public standard package
and think the atomic package should only be used inside standard pckages and runtime code.
</p>


atomic, CPU barriers, the instructions before and after a barrier ...


This article will not recommend any sync tech,
choose one by your own taste.


<div>
There are three basic data synchronization techniques in Go concurrent programming:
<ul>
<li>atomic operation,</li>
<li>mutex locking,</li> 
<li>channel communication.</li>
</ul>
</div>

<p>
Theoretically speaking,
mutex locking can be used for all the usage scenarios of atomic operations,
and channel communication can be used for all the usage scenarios of mutex locking.
Surely, these facts don't mean atomic operation and mutex locking are unnecessary.
In fact, atomic operation is more efficient than mutex locking and channel communication
for its specific usage scenarios, 
and mutex locking is more efficient than channel communication
for the specific usage scenarios of mutex locking.
</p>

<div>
Here is an example to use all of the three techniques for one same scenario:

</div>

<p>
</p>

<h3>Atomic Operations</h3>

<h3>Mutex Locking</h3>


embed:

	package main

	import "fmt"
	import "reflect"

	type T struct {
		x struct {
			y int
		}
	}

	func main() {
		var t T
		fmt.Println(reflect.TypeOf(&t.x))   // *struct { y int }
		fmt.Println(reflect.TypeOf((&t).x)) // struct { y int }
		
	}


<h3>Channel Communication</h3>

<hr/>

There are three data sync methods in Go: atomic operation, mutex and channel.

Different siuations 

Let's begin on how to use the three sync methods.

Mutex

BTW, now, mutex in Go has no TryLocking method.

Atomic

aotimic can be viewed as special mutex.

unsafe.Pointer.

Channel
aas

Here we will not explain the channel detailedly.

Notification based.

How To Choose Which One To Use?

aotimic package: fastest, but not flexible.
mutex: a general replacement for atimic.
channel: slow (comparily)



So how to choose a proper locking technoledge in pratice:
1. access cases, if possible, try to use atomic 
2. flow cases

Comparing To Java

Conclusion: cocurrent in Go is more powerful and flexible than Java.

<h3>sync.Cond, sync.Mutex and sync.WaitGroup, etc should not be copied</h3>

sync.Cond

<h3>sync.WaitGroup</h3>

Add adds delta, which may be negative, to the WaitGroup counter. 
If the counter becomes zero, all goroutines blocked on Wait are released. If the counter goes negative, Add panics.

Note that calls with a positive delta that occur when the counter 
is zero must happen before a Wait. Calls with a negative delta, 
or calls with a positive delta that start when the counter is 
greater than zero, may happen at any time. Typically this means 
the calls to Add should execute before the statement creating the 
goroutine or other event to be waited for. If a WaitGroup is reused 
to wait for several independent sets of events, new Add calls must 
happen after all previous Wait calls have returned. See the WaitGroup example. 

<h3>64-bit atomic operations require 64-bit alignment</h3>

	type WaitGroup struct {

		noCopy noCopy

	

		// 64-bit value: high 32 bits are counter, low 32 bits are waiter count.

		// 64-bit atomic operations require 64-bit alignment, but 32-bit

		// compilers do not ensure it. So we allocate 12 bytes and then use

		// the aligned 8 bytes in them as state.

		state1 [12]byte

		sema   uint32

	}

	

	func (wg *WaitGroup) state() *uint64 {

		if uintptr(unsafe.Pointer(&wg.state1))%8 == 0 {

			return (*uint64)(unsafe.Pointer(&wg.state1))

		} else {

			return (*uint64)(unsafe.Pointer(&wg.state1[4]))

		}

	}

<h3>Channel And Mutex Are Equivalent</h3>

for example:
* unique id generator
* ...

<h3>Try To Use atomic if it is convienient, then mutex if it is convienient, then channel</h3>

Three circle, atomic is a sub-circle in mutex, mutex is a sub-circle in channel.

If performance is more important, convienience should be put in the second place.


<h3>Every Synchronization Has A Cost</h3>

try to avoid data sharing among goroutines.
for example, 

-->
